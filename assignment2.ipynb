{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiT0fV9-W8bO",
        "colab_type": "text"
      },
      "source": [
        "# Assignment\n",
        "\n",
        "In this assignment we will train a multilayer perceptron model on the MNIST dataset, extending the linear (single-layer) classifier in the tutorial. \n",
        "\n",
        "This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBaRd_P9W8bT",
        "colab_type": "text"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Once complete, the following items must be submitted:\n",
        "\n",
        "* final `*.ipynb` notebook (push to https://github.com/[username]/cs190/mlp/assignment.ipynb)\n",
        "* final trained `*.hdf5` model file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this assignment. For those interested in running a local Jupyter server, please consider using one of the following options to ensure dependency compatibility:\n",
        "\n",
        "1. Precompiled Docker images: see https://github.com/peterchang77/install (**recommended**)\n",
        "2. Conda environment files: see https://github.com/peterchang77/dl_utils/tree/master/envs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq7fPp6ZW8bi",
        "colab_type": "text"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBQztneUW8bl",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive\n",
        "\n",
        "The Google Colab environment is transient and will reset after any prolonged break in activity. To retain important and/or large files between sessions, use the following lines of code to mount your personal Google drive to this Colab instance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J__yMaRnW8bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    # --- Mount gdrive to /content/drive/My Drive/\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "except: pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACBDGsbPW8cA",
        "colab_type": "text"
      },
      "source": [
        "Throughout this assignment we will use the following global `MOUNT_ROOT` variable to reference a location to store long-term data. If you are using a local Jupyter server and/or wish to store your data elsewhere, please update this variable now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4fKwc-EW8cC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Set data directory\n",
        "MOUNT_ROOT = '/content/drive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ8OMmSoW8cN",
        "colab_type": "text"
      },
      "source": [
        "### Select Tensorflow library version\n",
        "\n",
        "This assignment will use the (new) Tensorflow 2.0 library. Use the following line of code to select this updated version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZxtrzWzW8cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Select Tensorflow 2.0 (only in Google Colab)\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df5NTGHRW8cX",
        "colab_type": "text"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ-Oh2N8W8cY",
        "colab_type": "text"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKPGodnxW8cZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "08a48ee2-e545-42df-e6d6-efc1021da639"
      },
      "source": [
        "# --- Install jarvis (only in Google Colab or local runtime)\n",
        "% pip install jarvis-md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jarvis-md\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/72/1f859151f6059f40d469225eb9848fa72c6577beb657e24482996930ba08/jarvis_md-0.0.1a10-py3-none-any.whl (69kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (3.2.1)\n",
            "Collecting pyyaml>=5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (1.18.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from jarvis-md) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->jarvis-md) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->jarvis-md) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->jarvis-md) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->jarvis-md) (1.24.3)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=3fffae9d5eddd64538df8d202ef0fab4fbe60a7b0d4cc1994e2db46f97ae6324\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, jarvis-md\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed jarvis-md-0.0.1a10 pyyaml-5.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoxmm-c-W8cg",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any additional needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubkL4r5oW8ci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers\n",
        "from jarvis.train import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJQI538mW8cq",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "\n",
        "As in the tutorial, data for this assignment will consist of the MNIST handwritten digit dataset. The following lines of code will:\n",
        "\n",
        "1. Download the dataset (if not already present) \n",
        "2. Prepare the necessary Python generators to iterate through dataset\n",
        "3. Prepare the corresponding Tensorflow Input(...) objects for model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vAutD0cW8cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "dbc84c8d-549f-4325-fea2-bfe39d0ddbec"
      },
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='mnist')\n",
        "\n",
        "# --- Prepare generators and model inputs\n",
        "gen_train, _, client = datasets.prepare(name='mnist')\n",
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2020-05-31 06:18:19 ] [====================] 100.000% : Iterating | 000001    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp-3NQl5W8cv",
        "colab_type": "text"
      },
      "source": [
        "**Note**: There is no need to change the above code for this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0XDhHklW8cv",
        "colab_type": "text"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this assignment we will train a multilayer perceptron, e.g. a simple neural network with at least one hidden layer. Be creative; feel free to try various permutations of: \n",
        "\n",
        "* number(s) of hidden layer(s)\n",
        "* size of hidden layer(s)\n",
        "* learning rate\n",
        "* training iterations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MIrhY8BW8cw",
        "colab_type": "text"
      },
      "source": [
        "### Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSYxZOXoW8cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Define model\n",
        "h1 = layers.Dense(128, activation = 'relu')(inputs['dat'])\n",
        "h2 = layers.Dense(64, activation = 'relu')(h1)\n",
        "h3 = layers.Dense(32, activation = 'relu')(h2)\n",
        "\n",
        "logits = {}\n",
        "logits['digit'] = layers.Dense(10, name='digit')(h3)\n",
        "model = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HIo8r-PW8c0",
        "colab_type": "text"
      },
      "source": [
        "### Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-LAgPSQW8c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Define loss and optimizer\n",
        "loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = optimizers.Adam(learning_rate=1e-2)\n",
        "\n",
        "# --- Compile model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = {'digit' : loss},\n",
        "    metrics = {'digit' : 'sparse_categorical_accuracy'}\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rol_nf2kW8c8",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY_fCoX_W8c9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "fac53a30-e3c6-4c1f-846c-72ab7a5b37b4"
      },
      "source": [
        "model.fit_generator(\n",
        "    generator=gen_train, \n",
        "    steps_per_epoch=250, \n",
        "    epochs=4)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-2b71c2386331>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/4\n",
            "250/250 [==============================] - 26s 104ms/step - loss: 0.9547 - sparse_categorical_accuracy: 0.7235\n",
            "Epoch 2/4\n",
            "250/250 [==============================] - 26s 106ms/step - loss: 0.3895 - sparse_categorical_accuracy: 0.8902\n",
            "Epoch 3/4\n",
            "250/250 [==============================] - 26s 106ms/step - loss: 0.2939 - sparse_categorical_accuracy: 0.9169\n",
            "Epoch 4/4\n",
            "250/250 [==============================] - 26s 104ms/step - loss: 0.2669 - sparse_categorical_accuracy: 0.9233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f926027f7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x30Rjl9dW8dA",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the training data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j35og3qXW8dB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ac7a9e3-0af5-4f6f-9ba2-83797d4a7b31"
      },
      "source": [
        "# --- Calculate accuracy\n",
        "arrs = client.get(rows=np.arange(60000))\n",
        "pred = model.predict(arrs['xs']['dat'])\n",
        "\n",
        "# --- Serialize as *.csv file\n",
        "df = pd.DataFrame(index=client.db.fnames.index)\n",
        "df['true'] = arrs['ys']['digit'][:, 0]\n",
        "df['pred'] = np.argmax(pred['digit'], axis = 1)\n",
        "df['corr'] = df['true'] == df['pred']\n",
        "\n",
        "# --- Print cumulative model perforance\n",
        "df['corr'].mean()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf8cz0QfW8dE",
        "colab_type": "text"
      },
      "source": [
        "**Note**: this cell is used only to check for model performance. It will not be graded. Once you are satisfied with your model, proceed to submission of your assignment below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHpaPKViW8dE",
        "colab_type": "text"
      },
      "source": [
        "# Submission\n",
        "\n",
        "Use the following line to save your model for submission (in Google Colab this should save your model file into your personal Google Drive):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceyiij8W8dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --- Serialize a model\n",
        "fname = '{}/models/linear/final.hdf5'.format(MOUNT_ROOT)\n",
        "os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
        "model.save(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5iG-vsUW8dJ",
        "colab_type": "text"
      },
      "source": [
        "### Canvas\n",
        "\n",
        "Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n",
        "\n",
        "* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n",
        "* final (trained) model: `[UCInetID]_model.hdf5`\n",
        "\n",
        "**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooked file would be submitted under the name `panteater_notebook.ipynb` and his model file would be submitted under the name `panteater_model.hdf5`."
      ]
    }
  ]
}